{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP6JLo1tGNBg"
      },
      "source": [
        "# Bank Customer Churn Prediction (ANN) Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MxkJoQBkUIHC"
      },
      "outputs": [],
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import tensorflow as tf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ZaTwK7ojXr2F",
        "outputId": "6845cd2d-6e09-4e5a-d50d-3b97cbaa28f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.20.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__   # Tensorflow sürümünü kontrol ediyorum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX"
      },
      "source": [
        "## Part 1 - Data Preprocessing [Veri setimizde her şey sayı olmalı bu yüzden france , male gibi özellikleri aşağıdaki yöntemler ile sayısal karşılık ataması yapmamız gerekiyor]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z"
      },
      "source": [
        "### Importing the dataset (Veri setini içe aktarma)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# \"Churn_Modelling.csv\" adlı dosya aslında bir Excel dosyası\n",
        "dataset = pd.read_excel(\"Churn_Modelling.csv\", engine=\"openpyxl\")  # Data setimizi içe aktarıyoruz.\n",
        "\n",
        "X = dataset.iloc[:, 3:-1].values # Buradaki x fonksiyonumuzun x değeri diye düşünebilriiz veri girdisi. \".iloc\" Pandas fonksiyonu, DataFrame içindeki verilere endekslemek için kullanılır. [:, 3:-1] ifadesi, tüm satırları alır (:) ve sütunlarda 3. sütundan (indeks 3) başlayıp son sütundan bir öncekine kadar (-1 indeks) olan sütunları seçer. Çünkü ilk 3 sütun bizi modelimiz için gerekmiyor kullanıcının adı soyadı veya satır sayısı onun bankada kalıp kalmama durumuna etki etmez. Aslında sinir ağımız bunu kendisi de anlayabilir ancak eğitim sürecini hızlandırmak için bunu biz yapalım ve \".values\" DataFrame'in değerlerini Numpy array olarak döndürür.\n",
        "y = dataset.iloc[:, -1].values # Buradaki y değeri ise Veri setimizin en son satırlarında bulunan Exited değeri yani müşteri banka da kalacak mı kalmayacak mı ? yani f(x) = y değeridir. 1 ise müşteri bankadan ayrılmıştır 0 ise hala bankada kalıyor anlamına gelir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYP9cQTWbzuI",
        "outputId": "8937df92-c4c1-498b-bb08-ee34c9dba7c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 14)\n",
            "(10000, 10)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "print(dataset.shape)  # (10000, 14)\n",
        "print(X.shape)        # (10000, 10)\n",
        "print(y.shape)        # (10000,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6bQ0UgSU-NJ"
      },
      "source": [
        "### Encoding categorical data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le5MJreAbW52"
      },
      "source": [
        "Label Encoding the \"Gender\" column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PxVKWXxLbczC"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder # LabelEncoder sınıfını kullanarak kategorik verilerin (string veya obje olarak temsil edilen) sayısal değerlere dönüştürülmesini sağlar.\n",
        "le = LabelEncoder() # Bu sınıftan bir \"le\" oluşturdum veri dönüşümlerini yapmak için kullanılacak yöntemlere sahip olur.\n",
        "X[:, 2] = le.fit_transform(X[:, 2]) # X[:, 2] ifadesi, X veri setinin tüm satırlarını (:) ve 2. sütununu seçer. le.fit_transform(X[:, 2]) komutu ile veri setinin 2. sütununu sayısal değerlere dönüştürüp tekrar 2. sütuna yazar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M1KboxFb6OO",
        "outputId": "a89502e3-d0b9-45af-dfc0-666f88413e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[619 'France' 0 ... 1 1 101348.88]\n",
            " [608 'Spain' 0 ... 0 1 112542.58]\n",
            " [502 'France' 0 ... 1 0 113931.57]\n",
            " ...\n",
            " [709 'France' 0 ... 0 1 42085.58]\n",
            " [772 'Germany' 1 ... 1 0 92888.52]\n",
            " [792 'France' 0 ... 1 0 38190.78]]\n"
          ]
        }
      ],
      "source": [
        "print(X) # Makine rastgele olarak kadına 0 ve erkeğe 1 değerlerini atamış."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUxGZezpbMcb"
      },
      "source": [
        "One Hot Encoding the \"Geography\" column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AMXC8-KMVirw"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder # Ülke isimlerini 0 1 2 diye rastgele numaralandıramayız bu yüzden HotEncoder kullanmamız gerekiyor.\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough') # Dönüşüm yapılacak sütunun indeksini belirtiyoruz \"1\". ct adında bir kısa bir örnek oluşturuyoruz.\n",
        "X = np.array(ct.fit_transform(X)) # ct.fit_transform(X) yöntemi, X veri setini ColumnTransformer ile dönüştürür. Dönüşüm sonucu, X veri seti üzerine uygulanır ve dönüştürülmüş veriyi içeren bir Numpy array'i döndürür. np.array() fonksiyonu ile dönüşüm sonucu tekrar bir Numpy array'e dönüştürülür ve X değişkenine atılır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcxwEon-b8nV",
        "outputId": "7d6d8cd8-5988-4e17-9486-1d3f844fdb29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 ... 1 1 101348.88]\n",
            " [0.0 0.0 1.0 ... 0 1 112542.58]\n",
            " [1.0 0.0 0.0 ... 1 0 113931.57]\n",
            " ...\n",
            " [1.0 0.0 0.0 ... 0 1 42085.58]\n",
            " [0.0 1.0 0.0 ... 1 0 92888.52]\n",
            " [1.0 0.0 0.0 ... 1 0 38190.78]]\n"
          ]
        }
      ],
      "source": [
        "print(X) # Fransa 1.0 0.0 0.0 , Almanya 0.0 1.0 0.0 , İspanya 0.0 0.0 1.0 diye kodlanmış # Şuan burada cinsiyet sayıları [0 ve 1] gözükmüyor ama sıkıntı yok o hala o array in içinde sadece dizi uzun olduğu için gözükmüyor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set (Veri setini train ve test olacak şekilde ikiye ayıracağız)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Z-TDt0Y_XEfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0) # train_test_split fonksiyonu, dört değişken döndürür: X_train, X_test, y_train, ve y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ"
      },
      "source": [
        "### Feature Scaling (Özellik Ölçeklendirme)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ViCrE00rV8Sk"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler \n",
        "sc = StandardScaler() # sc adında kısa bir kullanım örneği oluşturduk.\n",
        "X_train = sc.fit_transform(X_train) # sc örneğini kullanarak fit_transform yöntemi, önce veriye fit (uygun hale getirme) işlemi yapar ve sonra veriyi dönüştürme (transform) işlemi uygular. X_train veri seti, StandardScaler ile fit edilir (yani ortalama ve standart sapma hesaplanır) ve dönüştürülür (standardizasyon yapılır).Bu işlem sonucunda, X_train içindeki her bir özellik (sütun) bağımsız olarak standart normal dağılıma göre ölçeklenmiş olur.\n",
        "X_test = sc.transform(X_test) # transform yöntemi, veriyi dönüştürme (transform) işlemi uygular. X_test veri seti, daha önce fit edilen StandardScaler ile dönüştürülür (standardizasyon yapılır). Burada X_test verisi, eğitim verisi olan X_train üzerinde fit edilen standartlaştırma parametreleri (ortalama ve standart sapma) kullanılarak dönüştürülür.\n",
        "# Test setinin eğitim setinden ayrı olduğunu unutmamak önemlidir; bu nedenle, test seti üzerinde yalnızca transform işlemi yapılır."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3dtrScHxXQox"
      },
      "outputs": [],
      "source": [
        "ann = tf.keras.models.Sequential() # Oluşturduğumuz sinir ağı bir sıralı sınıfın nesnesi olacaktır. ancak grafik şeklinde değil BİR DİZİ KATMAN şeklindedir.\n",
        "#  tf.keras.models 'u çağırdık çünkü bizim SIRALI SINIFI çağıracak olan fonksiyon budur.\n",
        "# SONUÇ OLARAK ANN imizi bir dizi katman olarak başlatan bir \"ann\" değişkenini oluşturduk.\n",
        "# sequential == sıralı demek sıralı sınıfımız budur. Bu sınıfın içinde kesinlikle ADD komutu olmalıdır buna dikkat edelim.\n",
        "# Sequential modeli, katmanları sıralı olarak eklememizi sağlayan bir yapıdır.\n",
        "\n",
        "# -- ÖNEMLİ --\n",
        "# Yapay sinir ağlarında, giriş katmanı (input layer) genellikle açıkça eklenmez çünkü bu katman, model oluşturulurken girdi verileri input layer olarak kabul edilir zaten ekli varsayılır.\n",
        "# Giriş katmanı, model oluşturulurken verilen ilk katman olarak kabul edilir.\n",
        "# Dolayısıyla, Sequential modeli oluşturulurken ilk katman eklenirken aynı zamanda giriş katmanı olarak kabul edilir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6urV6SX7kS"
      },
      "source": [
        "### Adding the input layer and the first hidden layer (İnput ve gizli katmanları eklemeye başlayalım)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bppGycBXYCQr"
      },
      "outputs": [],
      "source": [
        "#                                          SIĞ BİR SİNİR AĞI NASIL OLUŞTURULUR ?\n",
        "ann.add(tf.keras.layers.Dense(units=8, activation='relu')) # Gizli katman ekledim.katman sayısını artırarak ağımızı daha da derinleştirebiliriz.\n",
        "# ADD komutu ile herhangi bir şey bağladığımızda kullanırız ister hidden layer yani gizli katman olsun ister input layer olsun.\n",
        "# Veri setimizdeki her sütun bir input nöron olacaktır.\n",
        "# units=6: Bu parametre, katmandaki nöron sayısını belirtir. Burada, 6 adet nöron (veya birim) bulunan bir gizli katman ekleniyor.\n",
        "# activation='relu': Bu parametre, katmanın aktivasyon fonksiyonunu belirtir. 'relu' (Rectified Linear Activation) fonksiyonu, gizli katmanlarda sıkça kullanılan ve Rectifier (Doğrultucu fonksiyon , defterde notu grafiği mevcut) aktivasyon fonksiyonudur. Bu fonksiyonun kod adı 'relu' olarak kullanılır.\n",
        "# Bu fonksiyon, negatif girişlerde 0 çıktısı verirken, pozitif girişlerde girişi doğrudan geçirir.\n",
        "# units=6 bu komut katmandaki nöron sayısını belirtir. Burada, 6 adet nöron (veya birim) bulunan bir GİZLİ KATMAN ekleniyor.\n",
        "# Dense komutu katmanları birbirine bağlar önceki katmanlarla eklediğimiz katmanların bağlantısını yapar.\n",
        "\n",
        "# -- ÖNEMLİ --\n",
        "# Bir katmanda kaç nöron olması gerektiğini nasıl belirleriz ?\n",
        "# Bu tamamen tecrübeye dayanır bunun için geliştirilmiş bir formül yoktur.\n",
        "# Şimdilik bunu deneyerek ayarlamamız gerekiyor hangi sonucun doğruluk değeri daha yüksek ise o nöron sayısını seçeceğiz.\n",
        "# Ancak bu sayılar çok uçuk kaçık sayılar olmaması gerekiyor. Tabii ki veri setinize de bağlı ancak yine de büyük sayılar olmaz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BELWAc_8YJze"
      },
      "source": [
        "### Adding the others hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JneR0u0sYRTd"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=8, activation='relu')) # Bir diğer gizli katman ekledim.\n",
        "# İstersem projeye göre bu değerleri değiştirebilirim ya da nöron sayını modelinin doğruluk yüzdesini artırmak için güncelleyebilirim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=8, activation='relu')) # Bir diğer gizli katman ekledim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNEe6RXYcU4"
      },
      "source": [
        "### Adding the output layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Cn3x41RBYfvY"
      },
      "outputs": [],
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "# Sonuçta yeni bir katman eklediğimiz için \"ann.add(tf.keras.layers.Dense\" buraya kadar olan kısım aynı\n",
        "# 2 sınıf sonucu kullandığımız için tek çıkış nöranu tercih ettik yani \"units=1\" oldu. genelden evet hayır doğru yanlış hasta sağlıklı gibi çift sonuçlu veri setlerinde tek çıkış nöronu kullanılır.\n",
        "# İkiden çok sınıf ve İkiden çok çıktı değeri olan sinir ağlarında daha fazla nöron sayısı kullanabiliriz.\n",
        "# Sigmoid fonksiyonu defterde de anlattım 0'a ve 1'e giderek yaklaşan orada bir olasılık değeri veren aktivasyon fonksiyonu sigmoidin kullanımı çift olasılıklı sinir ağlarında yaygındır.\n",
        "\n",
        "# --- ÖNEMLİ ---\n",
        "# YANİ SONUÇ OLARAK sigmoid fonksiyonu sayesinde her müşterinin bankadan ayrılıp ayrılmayacağını 0 ve 1 olarak bulmayacağız 0 ve 1 olma olasılıklarını bulacağız. yani her müşterinin bankadan ayrılıp ayrılmama olasılıklarını yüzde olarak görebileceğiz.\n",
        "# Bu yüzden sigmoid fonksiyonunu kullanıyoruz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT4u2S1_Y4WG"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GWlJChhY_ZI"
      },
      "source": [
        "### Compiling the ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fG3RrwDXZEaS"
      },
      "outputs": [],
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "# Genelde \"adam\" optimizerı tercih edilir çünkü sthokastik Gradyan İnişini kullandığı için oldukça yüksek performans veren bir optimezerdır. Bu yöntem ile ağırlıkları güncelleyecektir.\n",
        "# Tahminler ve Gerçek sonuçlar arasındaki kayıp fonksiyonunu bulmak için \"loss\" fonksiyonunu kullanıyoruz.\n",
        "# 0 ve 1 kullanarak ikili sınıflandırma yapan bir sinir ağı ile çalıştığımız için loss = binary_crossentropy olmalıdır.\n",
        "# Metrics, modelin performansını ölçmek ve değerlendirmek için kullanılır.\n",
        "# Aynı anda birden fazla metrics se.ebileceğimiz için [] kullanılır. metrics genelde accuarry seçilir.\n",
        "# Eğer ikili sınıfkandırmanın dışında çok daha çeşitli sınıfkandırmalar yapan bir ağ üzerinde çalışsaydık :\n",
        "\n",
        "# ann.add(tf.keras.layers.Dense(units=3, activation='softmax'))\n",
        "# ann.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# optimizer olarak genellikle \"adam\" gibi bir optimizasyon algoritması kullanılır. metrics ise genellikle doğruluk accuracy olarak ayarlanır, ancak isteğe bağlı olarak farklı metrikler de seçilebilir.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM"
      },
      "source": [
        "### Training the ANN on the Training set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHZ-LKv_ZRb3",
        "outputId": "22f12cf7-155d-43a2-8e3f-e09c901953e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888us/step - accuracy: 0.7941 - loss: 0.5044\n",
            "Epoch 2/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.7960 - loss: 0.4630\n",
            "Epoch 3/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.7960 - loss: 0.4447\n",
            "Epoch 4/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.7960 - loss: 0.4355\n",
            "Epoch 5/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.7964 - loss: 0.4292\n",
            "Epoch 6/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.8031 - loss: 0.4222\n",
            "Epoch 7/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.8101 - loss: 0.4147\n",
            "Epoch 8/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.8131 - loss: 0.4075\n",
            "Epoch 9/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.8154 - loss: 0.4003\n",
            "Epoch 10/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.8163 - loss: 0.3928\n",
            "Epoch 11/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.8259 - loss: 0.3846\n",
            "Epoch 12/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.8365 - loss: 0.3776\n",
            "Epoch 13/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.8410 - loss: 0.3715\n",
            "Epoch 14/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.8439 - loss: 0.3661\n",
            "Epoch 15/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8469 - loss: 0.3613\n",
            "Epoch 16/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.8474 - loss: 0.3585\n",
            "Epoch 17/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8482 - loss: 0.3555\n",
            "Epoch 18/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.8484 - loss: 0.3542\n",
            "Epoch 19/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.8530 - loss: 0.3515\n",
            "Epoch 20/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8530 - loss: 0.3501\n",
            "Epoch 21/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.8539 - loss: 0.3482\n",
            "Epoch 22/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8536 - loss: 0.3466\n",
            "Epoch 23/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.8550 - loss: 0.3457\n",
            "Epoch 24/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.8574 - loss: 0.3446\n",
            "Epoch 25/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.8565 - loss: 0.3433\n",
            "Epoch 26/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8591 - loss: 0.3423\n",
            "Epoch 27/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.8593 - loss: 0.3414\n",
            "Epoch 28/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8596 - loss: 0.3396\n",
            "Epoch 29/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8593 - loss: 0.3394\n",
            "Epoch 30/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8606 - loss: 0.3380\n",
            "Epoch 31/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.8594 - loss: 0.3376\n",
            "Epoch 32/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.8612 - loss: 0.3373\n",
            "Epoch 33/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.8620 - loss: 0.3368\n",
            "Epoch 34/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.8612 - loss: 0.3352\n",
            "Epoch 35/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.8622 - loss: 0.3356\n",
            "Epoch 36/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.8633 - loss: 0.3347\n",
            "Epoch 37/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8640 - loss: 0.3339\n",
            "Epoch 38/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.8624 - loss: 0.3343\n",
            "Epoch 39/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.8626 - loss: 0.3328\n",
            "Epoch 40/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.8633 - loss: 0.3325\n",
            "Epoch 41/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.8637 - loss: 0.3324\n",
            "Epoch 42/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.8611 - loss: 0.3318\n",
            "Epoch 43/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8637 - loss: 0.3312\n",
            "Epoch 44/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.8640 - loss: 0.3309\n",
            "Epoch 45/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.8620 - loss: 0.3306\n",
            "Epoch 46/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.8621 - loss: 0.3314\n",
            "Epoch 47/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.8626 - loss: 0.3309\n",
            "Epoch 48/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.8625 - loss: 0.3299\n",
            "Epoch 49/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.8644 - loss: 0.3298\n",
            "Epoch 50/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.8624 - loss: 0.3294\n",
            "Epoch 51/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.8627 - loss: 0.3298\n",
            "Epoch 52/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.8635 - loss: 0.3295\n",
            "Epoch 53/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.8631 - loss: 0.3295\n",
            "Epoch 54/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.8635 - loss: 0.3287\n",
            "Epoch 55/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.8627 - loss: 0.3296\n",
            "Epoch 56/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.8621 - loss: 0.3282\n",
            "Epoch 57/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8636 - loss: 0.3287\n",
            "Epoch 58/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.8648 - loss: 0.3283\n",
            "Epoch 59/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.8645 - loss: 0.3281\n",
            "Epoch 60/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.8640 - loss: 0.3279\n",
            "Epoch 61/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.8629 - loss: 0.3275\n",
            "Epoch 62/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.8648 - loss: 0.3272\n",
            "Epoch 63/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8645 - loss: 0.3280\n",
            "Epoch 64/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.8635 - loss: 0.3278\n",
            "Epoch 65/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.8659 - loss: 0.3274\n",
            "Epoch 66/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.8654 - loss: 0.3275\n",
            "Epoch 67/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.8643 - loss: 0.3275\n",
            "Epoch 68/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.8635 - loss: 0.3273\n",
            "Epoch 69/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.8659 - loss: 0.3268\n",
            "Epoch 70/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.8634 - loss: 0.3268\n",
            "Epoch 71/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.8660 - loss: 0.3264\n",
            "Epoch 72/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8658 - loss: 0.3263\n",
            "Epoch 73/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 0.3269\n",
            "Epoch 74/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.8641 - loss: 0.3261\n",
            "Epoch 75/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.8658 - loss: 0.3265\n",
            "Epoch 76/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8674 - loss: 0.3256\n",
            "Epoch 77/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.8652 - loss: 0.3257\n",
            "Epoch 78/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.8645 - loss: 0.3257\n",
            "Epoch 79/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.8635 - loss: 0.3255\n",
            "Epoch 80/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.8656 - loss: 0.3258\n",
            "Epoch 81/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.8665 - loss: 0.3250\n",
            "Epoch 82/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.8658 - loss: 0.3253\n",
            "Epoch 83/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.8655 - loss: 0.3245\n",
            "Epoch 84/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.8659 - loss: 0.3254\n",
            "Epoch 85/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.8660 - loss: 0.3248\n",
            "Epoch 86/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.8656 - loss: 0.3250\n",
            "Epoch 87/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.8650 - loss: 0.3251\n",
            "Epoch 88/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8650 - loss: 0.3254\n",
            "Epoch 89/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.8651 - loss: 0.3248\n",
            "Epoch 90/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.8654 - loss: 0.3248\n",
            "Epoch 91/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8651 - loss: 0.3247\n",
            "Epoch 92/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.8651 - loss: 0.3241\n",
            "Epoch 93/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8664 - loss: 0.3238\n",
            "Epoch 94/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8659 - loss: 0.3247\n",
            "Epoch 95/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.8658 - loss: 0.3239\n",
            "Epoch 96/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.8659 - loss: 0.3245\n",
            "Epoch 97/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.8656 - loss: 0.3244\n",
            "Epoch 98/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.8666 - loss: 0.3242\n",
            "Epoch 99/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8674 - loss: 0.3235\n",
            "Epoch 100/100\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.8673 - loss: 0.3232\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2640d933fd0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)\n",
        "# \"fit\": Modelin eğitim verileri üzerinde eğitilmesini sağlayan yöntemdir.\n",
        "# batch_size=32: genelde 32 seçilir. Mini-batch gradient descent yöntemiyle eğitim yapılırken kullanılacak batch boyutunu belirtir. Batch boyutu, her bir eğitim adımında kullanılacak örnek sayısını ifade eder. Küçük batch boyutları daha fazla bellek kullanımına neden olur ancak daha hızlı eğitim sağlayabilirken, büyük batch boyutları daha az bellek kullanır ancak eğitim süresi uzayabilir.\n",
        "# epochs=100: Eğitim için kullanılacak epoch sayısını belirtir. Bir epoch, tüm eğitim verilerinin model tarafından bir kez geçirilmesini ifade eder. Epoch sayısı, modelin ne kadar süre boyunca eğitileceğini belirler.\n",
        "# Epoch sayısını belirlerken, modelinizin doğruluğunu artırması ve overfitting (aşırı uyum) veya underfitting (yetersiz uyum) gibi problemleri minimize etmesi önemlidir.\n",
        "# epoch değerini de veri setinin büyüklüğüne göre belirlemek iyi olacaktır.  Veri setiniz ne kadar büyükse, genellikle daha fazla epoch sayısı gerekebilir. Daha büyük veri setleri, modelin daha fazla örüntüyü öğrenmesi için daha fazla zaman gerektirir.\n",
        "# Ancak yine de en iyi en optimize epoch değerini belirlemek yine deneme yanılmadan geçer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Her şey 'artifacts_20251028-183617' klasörüne kaydedildi.\n",
            "Dosyalar:\n",
            "- column_transformer.pkl\n",
            "- FatihAybsn.keras\n",
            "- feature_names.json\n",
            "- label_gender.pkl\n",
            "- model_summary.txt\n",
            "- README.txt\n",
            "- scaler.pkl\n"
          ]
        }
      ],
      "source": [
        "# === KAYDETME HÜCRESİ — Eğitimin hemen ardından çalıştırın ===\n",
        "import os, sys, json, pickle\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "MODEL_VAR_NAME = None  \n",
        "\n",
        "run_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "out_dir = f\"artifacts_{run_id}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "# 1) Keras modelini bul\n",
        "_model = None\n",
        "model_name = None\n",
        "if MODEL_VAR_NAME and MODEL_VAR_NAME in globals():\n",
        "    _model = globals()[MODEL_VAR_NAME]\n",
        "    model_name = MODEL_VAR_NAME\n",
        "else:\n",
        "    for name, obj in list(globals().items()):\n",
        "        if isinstance(obj, tf.keras.Model):\n",
        "            _model = obj\n",
        "            model_name = name\n",
        "            break\n",
        "if _model is None:\n",
        "    raise RuntimeError(\"Eğitilmiş Keras modeli bulunamadı. MODEL_VAR_NAME = 'model' gibi ayarlayıp tekrar dene.\")\n",
        "\n",
        "# 2) Modeli kaydet (.keras önerilen format)\n",
        "model_path = os.path.join(out_dir, \"FatihAybsn.keras\")\n",
        "_model.save(model_path)\n",
        "\n",
        "# 3) Model özetini yaz\n",
        "with open(os.path.join(out_dir, \"model_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    _model.summary(print_fn=lambda s: f.write(s + \"\\n\"))\n",
        "\n",
        "# 4) Eğitim geçmişi (history) varsa kaydet ve eğriyi PNG olarak çıkar\n",
        "hist_obj = globals().get(\"history\", None)\n",
        "if hist_obj is not None and hasattr(hist_obj, \"history\"):\n",
        "    history_dict = hist_obj.history\n",
        "    with open(os.path.join(out_dir, \"history.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(history_dict, f, ensure_ascii=False, indent=2)\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.figure()\n",
        "        if \"loss\" in history_dict: plt.plot(history_dict[\"loss\"], label=\"loss\")\n",
        "        if \"val_loss\" in history_dict: plt.plot(history_dict[\"val_loss\"], label=\"val_loss\")\n",
        "        if \"accuracy\" in history_dict: plt.plot(history_dict.get(\"accuracy\", []), label=\"accuracy\")\n",
        "        if \"val_accuracy\" in history_dict: plt.plot(history_dict.get(\"val_accuracy\", []), label=\"val_accuracy\")\n",
        "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Metric\"); plt.legend(); plt.tight_layout()\n",
        "        plt.savefig(os.path.join(out_dir, \"training_curves.png\"), dpi=150)\n",
        "        plt.close()\n",
        "    except Exception as e:\n",
        "        print(\"Eğitim grafiği kaydedilemedi:\", e)\n",
        "\n",
        "# 5) Ön-işleme nesneleri (varsa) kaydet\n",
        "to_pickle = {\n",
        "    \"scaler\": globals().get(\"sc\") or globals().get(\"scaler\") or globals().get(\"sc_X\"),\n",
        "    \"column_transformer\": globals().get(\"ct\"),\n",
        "    \"onehot_geography\": globals().get(\"ohe_geo\") or globals().get(\"ohe\") or globals().get(\"onehot\"),\n",
        "    \"label_gender\": globals().get(\"le_gender\") or globals().get(\"le\"),\n",
        "}\n",
        "for name, obj in to_pickle.items():\n",
        "    if obj is not None:\n",
        "        with open(os.path.join(out_dir, f\"{name}.pkl\"), \"wb\") as f:\n",
        "            pickle.dump(obj, f)\n",
        "\n",
        "# 6) Özellik isimleri (varsa) kaydet\n",
        "feature_names = None\n",
        "X_train = globals().get(\"X_train\")\n",
        "try:\n",
        "    if X_train is not None and hasattr(X_train, \"columns\"):  # DataFrame ise\n",
        "        feature_names = list(X_train.columns)\n",
        "    else:\n",
        "        ct = to_pickle.get(\"column_transformer\")\n",
        "        if ct is not None and hasattr(ct, \"get_feature_names_out\"):\n",
        "            feature_names = list(ct.get_feature_names_out())\n",
        "    if feature_names is not None:\n",
        "        with open(os.path.join(out_dir, \"feature_names.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(feature_names, f, ensure_ascii=False, indent=2)\n",
        "except Exception as e:\n",
        "    print(\"Özellik isimleri kaydedilemedi:\", e)\n",
        "\n",
        "# 7) Ortam bilgisi ve kısa talimat\n",
        "info = {\n",
        "    \"run_id\": run_id,\n",
        "    \"model_variable\": model_name,\n",
        "    \"python\": sys.version,\n",
        "    \"tensorflow\": tf.__version__,\n",
        "}\n",
        "try:\n",
        "    import sklearn\n",
        "    info[\"scikit_learn\"] = sklearn.__version__\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "with open(os.path.join(out_dir, \"README.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\n",
        "        \"Bu klasör, churn ANN eğitimi sonrası üretilen artefaktları içerir.\\n\"\n",
        "        f\"- Model: {os.path.basename(model_path)}\\n\"\n",
        "        \"- Ön-işleme nesneleri: *.pkl (varsa)\\n\"\n",
        "        \"- Eğitim geçmişi: history.json ve training_curves.png (varsa)\\n\"\n",
        "        \"- Özellik isimleri: feature_names.json (varsa)\\n\\n\"\n",
        "        \"Yükleme örneği:\\n\"\n",
        "        \"import tensorflow as tf, pickle\\n\"\n",
        "        f\"model = tf.keras.models.load_model(r'{model_path}')\\n\"\n",
        "        \"# scaler/ct/encoders için: pickle.load(open('...pkl','rb'))\\n\"\n",
        "    )\n",
        "\n",
        "print(f\"✓ Her şey '{out_dir}' klasörüne kaydedildi.\")\n",
        "print('Dosyalar:', *os.listdir(out_dir), sep=\"\\n- \")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gWZyYmS_UE_L",
        "1E0Q3aoKUCRX",
        "-zfEzkRVXIwF",
        "tJj5k2MxZga3"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
